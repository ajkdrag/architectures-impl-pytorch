{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4057702-f758-4400-a770-0ddeecc90895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ec40f2-de6b-42dc-a604-75c10508f566",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## vectorizing encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1c424507-6b99-4158-911d-cdbd9084815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = torch.tensor([0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b1373299-56d7-4a5f-b27d-1cf3800d5f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_conf = torch.rand(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bb812382-1dd2-4879-92a7-44d4e8c0ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = torch.cat([i.unsqueeze(1),wh_conf], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "26ce9adb-936e-467e-bf45-e90046cac56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.9579, 0.3726, 0.7087, 0.7728],\n",
       "        [0.0000, 0.2611, 0.2287, 0.2003, 0.9335],\n",
       "        [1.0000, 0.3852, 0.4650, 0.8816, 0.4901]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "65cc7fc3-a401-4754-931c-acf1baa4cf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = encode_labelsv2(boxes, 3, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4e6d554e-de9e-4aba-bfb3-a5ea4f51d673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 0\n",
      "0 0 0\n",
      "0 0 1\n"
     ]
    }
   ],
   "source": [
    "out2 = encode_labels(boxes, 3, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6cb024b2-1eb3-4ff5-a68c-a1bd6e15ec56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1668,  0.6598,  0.9389,  0.7000,  1.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  1.0000,  1.0000],\n",
       "         [ 0.8105, -0.0414,  0.8419,  0.8791,  1.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "171aa853-d705-443f-9b88-ee96a4b66cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1668,  0.6598,  0.9389,  0.7000,  1.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "         [ 0.8105, -0.0414,  0.8419,  0.8791,  1.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  1.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "df3bd188-3d87-4070-a16e-828db2474155",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = boxes[:, 0].long()\n",
    "cx, cy = boxes[:, 1], boxes[:, 2]\n",
    "w, h = boxes[:, 3], boxes[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ba4790be-24d6-4f2d-ac82-29bd9948b8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = cx - w * 0.5, cy - h * 0.5\n",
    "\n",
    "# Calculate the cell indices\n",
    "i, j = (3 * y).long(), (3 * x).long()\n",
    "\n",
    "# Calculate the cell-relative coordinates\n",
    "x_cell, y_cell = 3 * x - j, 3 * y - i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ae034aea-1695-4b6c-866f-b410e61d8b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = torch.stack((x_cell, y_cell, torch.sqrt(w), torch.sqrt(h), torch.ones_like(x_cell)), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2bd58b08-cd98-45cd-b7d1-8c64e1362da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5]), torch.Size([3]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.shape, class_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "346abdc1-62f9-4d05-a603-ccf06c0e941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_probs = torch.zeros((boxes.shape[0], 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5797009a-591b-4d90-b251-908696ae574a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0618168b-4420-45f4-9c09-2b0bdfe11ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_probs.scatter_(1, class_labels.unsqueeze(1), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bc2ac7db-52e7-4d61-ad7e-234786af8877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((stacked, class_probs), dim=-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7082b2f2-5ed5-45f9-a07c-13e71884f1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def encode_labelsv2(labels: torch.Tensor, S, B, C) -> torch.Tensor:\n",
    "    \"\"\"SxS grid according to yolo algorithm\n",
    "    labels: tensor of shape [N, 5]\n",
    "    \"\"\"\n",
    "    encoded_labels = torch.zeros((S, S, B * 5 + C))\n",
    "\n",
    "    # shapes: torch.Size([N]))\n",
    "    class_labels = labels[:, 0].int()\n",
    "    cx, cy = labels[:, 1], labels[:, 2]\n",
    "    w, h = labels[:, 3], labels[:, 4]\n",
    "    x, y = cx - w * 0.5, cy - h * 0.5\n",
    "\n",
    "    # Calculate the cell indices and cell-rel coords\n",
    "    i, j = (S * y).int(), (S * x).int()\n",
    "    x_cell, y_cell = S * x - j, S * y - i\n",
    "\n",
    "    # stacked shape: torch.Size([N, 5])\n",
    "    boxes = torch.stack((x_cell, y_cell, torch.sqrt(w), torch.sqrt(h), torch.ones_like(x_cell)), dim=-1)\n",
    "\n",
    "    # Create a tensor to store the class probabilities (OHE)\n",
    "    # scatter_ puts 1 on indices defined by class_labels.unsqueeze(1)\n",
    "    # OHE shape: torch.Size([N, C])\n",
    "    class_probs = torch.zeros((labels.shape[0], C))\n",
    "    class_probs.scatter_(1, class_labels.unsqueeze(1), 1)\n",
    "\n",
    "    # No matter what B is, we make only the first box responsible\n",
    "    encoded_labels[i, j, :5] = boxes\n",
    "    encoded_labels[i, j, -C:] = class_probs\n",
    "\n",
    "    return encoded_labels\n",
    "\n",
    "\n",
    "def encode_labels(labels: torch.Tensor, S, B, C) -> torch.Tensor:\n",
    "    \"\"\"SxS grid according to yolo algorithm\n",
    "    labels: tensor of shape [N, 5]\n",
    "    \"\"\"\n",
    "    encoded_labels = torch.zeros((S, S, B * 5 + C))\n",
    "    for label in labels:\n",
    "        class_label, cx, cy, w, h = label\n",
    "        x, y = cx - w * 0.5, cy - h * 0.5\n",
    "        class_label = int(class_label)\n",
    "        \n",
    "        i, j = int(S * y), int(S * x)\n",
    "        x_cell, y_cell = S * x - j, S * y - i\n",
    "\n",
    "        # set the first box with true labels\n",
    "        encoded_labels[i, j, 0:4] = torch.tensor(\n",
    "            [x_cell, y_cell, torch.sqrt(w), torch.sqrt(h)]\n",
    "        )\n",
    "        # Object conf set to 1 for simplificty\n",
    "        # replace with IoU during loss computation\n",
    "        encoded_labels[i, j, 4] = 1\n",
    "        print(i, j, class_label)\n",
    "        # Encode the class probabilities (OHE)\n",
    "        encoded_labels[i, j, -C + class_label] = 1\n",
    "\n",
    "    return encoded_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b095586e-a18e-4ec1-aae4-c9522d37a911",
   "metadata": {},
   "source": [
    "## vectorizing decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63f1ef6a-e31a-49c7-b76a-90cb9d96a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dimensions\n",
    "B = 3\n",
    "C = 2\n",
    "x = torch.randn(10, B*5 + C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e42785bf-0384-4983-a8f7-744fe0424c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.9616,  0.1236,  2.7516,  1.6306,  0.6964, -0.7375, -0.2009,  0.4031,\n",
       "         1.7019,  1.4073, -0.2385, -0.0675,  1.5605,  0.3064,  1.6552,  1.0706,\n",
       "        -0.5794])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9c69cd7-a949-4cec-b6b9-9e0228c34915",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = x[..., :B*5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "091d919b-d598-4452-b04b-d98dd21383a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "confs = x[..., -C:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d27dd5d4-989d-4251-bb0b-75b460a43f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0706, -0.5794],\n",
       "        [-1.3386, -1.6600],\n",
       "        [ 0.2133,  2.7711],\n",
       "        [-1.3419,  1.0153],\n",
       "        [-0.5589,  1.9114],\n",
       "        [ 0.2992, -0.6253],\n",
       "        [-0.7575,  1.1813],\n",
       "        [ 1.2572, -2.1036],\n",
       "        [-0.3777, -1.4239],\n",
       "        [-0.1400, -0.1314]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfed201e-7e8d-4438-9b05-087f9a5f20f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs.repeat_interleave(B, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32965db2-8970-41c7-81f9-cfe089ae96d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72a78904-26f7-4339-8402-506c8abfe2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "repeat(*sizes) -> Tensor\n",
       "\n",
       "Repeats this tensor along the specified dimensions.\n",
       "\n",
       "Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
       "\n",
       ".. warning::\n",
       "\n",
       "    :meth:`~Tensor.repeat` behaves differently from\n",
       "    `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
       "    but is more similar to\n",
       "    `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
       "    For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
       "\n",
       "Args:\n",
       "    sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
       "        dimension\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> x = torch.tensor([1, 2, 3])\n",
       "    >>> x.repeat(4, 2)\n",
       "    tensor([[ 1,  2,  3,  1,  2,  3],\n",
       "            [ 1,  2,  3,  1,  2,  3],\n",
       "            [ 1,  2,  3,  1,  2,  3],\n",
       "            [ 1,  2,  3,  1,  2,  3]])\n",
       "    >>> x.repeat(4, 2, 1).size()\n",
       "    torch.Size([4, 2, 3])\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confs.repeat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ed0da7f-8872-4cac-89d3-a53709f8e59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.9616,  0.1236,  2.7516,  1.6306,  0.6964, -0.7375, -0.2009,  0.4031,\n",
       "         1.7019,  1.4073, -0.2385, -0.0675,  1.5605,  0.3064,  1.6552])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9aae48b-e099-4f4c-8024-5e8c9fd26372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.9616, 0.1236, 2.7516, 1.6306, 0.6964])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes.reshape(10*B, -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "565fa649-47e0-44e6-bda3-1cb19e6e91f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2385, -0.0675,  1.5605,  0.3064,  1.6552])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes.reshape(10*B, -1)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea425798-a006-4a11-a288-95e8ea109707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes.reshape(10*B, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943e774f-dbab-4014-88b7-a01666b08675",
   "metadata": {},
   "outputs": [],
   "source": [
    "confs.repeat_interleave(B, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a49184a-2c9a-4778-8f23-8c73fb2bfab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_probs = confs.repeat_interleave(B, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fdaef77c-c161-478c-826d-47984f9f2bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = boxes.reshape(10*B, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35f4cfda-58b2-4fe8-8373-bdd8fb3a4086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([30, 5]), torch.Size([30, 2]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes.shape, class_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831d3507-f60e-41f3-a4af-6dc463aec595",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = torch.cat([boxes, class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8e12bc0c-efb0-4f57-b733-b0b85a891fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_probs, class_idx = torch.max(confs,dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e7f4fb5a-4aa8-4053-bb7b-9562235acfe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "14b09076-21f8-47b6-b1e3-4363803865b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0706],\n",
       "        [-1.3386],\n",
       "        [ 2.7711],\n",
       "        [ 1.0153],\n",
       "        [ 1.9114],\n",
       "        [ 0.2992],\n",
       "        [ 1.1813],\n",
       "        [ 1.2572],\n",
       "        [-0.3777],\n",
       "        [-0.1314]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ffc0224e-920e-4f85-928d-6fd9cf21f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_idx_rep = class_idx.repeat_interleave(B, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "685e116a-a074-4c00-b123-5db71271abb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_idx_rep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "82c2c34b-2e7b-467f-b3b2-f869fa230d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.9616,  0.1236,  2.7516,  1.6306,  0.6964,  0.0000],\n",
       "        [-0.7375, -0.2009,  0.4031,  1.7019,  1.4073,  0.0000],\n",
       "        [-0.2385, -0.0675,  1.5605,  0.3064,  1.6552,  0.0000],\n",
       "        [-0.7461,  1.6173,  0.2564,  0.4192, -0.0912,  0.0000],\n",
       "        [ 1.3360, -0.3270,  0.7847,  0.5295,  0.4127,  0.0000],\n",
       "        [ 0.5834, -1.7876,  2.3975,  0.8374, -0.0284,  0.0000],\n",
       "        [-0.2077,  1.7653,  1.1105,  0.3915, -0.5637,  1.0000],\n",
       "        [ 0.8680,  0.9730, -1.3465, -1.0940,  0.1654,  1.0000],\n",
       "        [-0.0132, -0.2464, -0.0919, -0.7040,  1.6186,  1.0000],\n",
       "        [ 1.8175,  1.7617,  2.6011,  0.5624, -0.3884,  1.0000],\n",
       "        [-1.0491, -0.0615, -2.2598,  1.7637, -0.5039,  1.0000],\n",
       "        [ 0.4838, -0.1474,  0.7951, -0.2404,  0.3210,  1.0000],\n",
       "        [ 0.4940,  0.9573,  0.5390,  0.6672, -1.2127,  1.0000],\n",
       "        [ 2.0386, -1.5385, -0.4422,  0.5366, -0.0364,  1.0000],\n",
       "        [ 1.6713,  0.6843, -0.4253, -1.4757, -0.8788,  1.0000],\n",
       "        [ 0.6084, -0.0284, -0.0777, -0.1334, -0.0643,  0.0000],\n",
       "        [ 0.8676,  1.9804, -1.1427, -0.3883,  0.4754,  0.0000],\n",
       "        [ 0.5579,  0.8255, -0.9309, -1.0015, -0.5988,  0.0000],\n",
       "        [-1.2994,  0.9025,  0.5690,  2.0148,  0.0045,  1.0000],\n",
       "        [-1.1147,  0.2018,  0.4597,  2.2150, -0.5726,  1.0000],\n",
       "        [ 1.9200,  0.5240, -0.3081, -0.8405,  0.3936,  1.0000],\n",
       "        [ 1.1095,  0.5399,  1.8982, -0.5818,  2.1945,  0.0000],\n",
       "        [ 0.6173, -1.5909,  1.4408, -0.0919,  0.1807,  0.0000],\n",
       "        [ 0.7706,  0.8879,  1.3174,  0.2000,  1.9321,  0.0000],\n",
       "        [ 0.9413,  0.0959,  0.5660, -2.0580, -0.8493,  0.0000],\n",
       "        [-0.4728, -0.1852, -1.3460, -0.7432, -1.5461,  0.0000],\n",
       "        [-0.3669, -2.4379, -0.3864,  0.6007,  1.8136,  0.0000],\n",
       "        [ 1.2372,  1.5066, -0.0757, -1.2273,  2.4522,  1.0000],\n",
       "        [-0.0381,  0.9753, -1.6047,  0.3814,  1.1929,  1.0000],\n",
       "        [ 0.2677,  1.5548,  0.1313,  2.0927, -0.4854,  1.0000]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([boxes, class_idx_rep], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "579bbeab-6e23-4533-bde4-a946221f2c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_587/4257354964.py:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  i_ = torch.range(0, 9)\n"
     ]
    }
   ],
   "source": [
    "i_ = torch.range(0, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7e25a59a-4cca-414b-83a9-82114583bec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9., 0., 1., 2., 3., 4., 5., 6., 7.,\n",
       "        8., 9., 0., 1., 2., 3., 4., 5., 6., 7., 8., 9., 0., 1., 2., 3., 4., 5.,\n",
       "        6., 7., 8., 9., 0., 1., 2., 3., 4., 5., 6., 7., 8., 9., 0., 1., 2., 3.,\n",
       "        4., 5., 6., 7., 8., 9., 0., 1., 2., 3., 4., 5., 6., 7., 8., 9., 0., 1.,\n",
       "        2., 3., 4., 5., 6., 7., 8., 9., 0., 1., 2., 3., 4., 5., 6., 7., 8., 9.,\n",
       "        0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_.repeat(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1c1d8f2b-fbde-4f25-9674-9e85c320d039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0706, -0.5794],\n",
       "        [-1.3386, -1.6600],\n",
       "        [ 0.2133,  2.7711],\n",
       "        [-1.3419,  1.0153],\n",
       "        [-0.5589,  1.9114],\n",
       "        [ 0.2992, -0.6253],\n",
       "        [-0.7575,  1.1813],\n",
       "        [ 1.2572, -2.1036],\n",
       "        [-0.3777, -1.4239],\n",
       "        [-0.1400, -0.1314]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d2bf054d-b1a7-4a73-829b-78d232347a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5794, -1.6600,  2.7711,  1.0153,  1.9114, -0.6253,  1.1813, -2.1036,\n",
       "        -1.4239, -0.1314])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs[..., 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b93da19f-94bc-4ac7-a660-b52e41872e18",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TensorBase.square_() takes no arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconfs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msquare_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: TensorBase.square_() takes no arguments (1 given)"
     ]
    }
   ],
   "source": [
    "confs[..., 1].pow_(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5b374118-17d8-465d-a8be-3658d4b602d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_.repeat_interleave(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "7cb258c8-8535-4d7a-ba04-ac34f34a9ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_labelsv0(\n",
    "    encoded_labels,\n",
    "    S,\n",
    "    B,\n",
    "    C,\n",
    "    conf_th=0.1,\n",
    "    nms=False,\n",
    "    iou_th=0.5,\n",
    "):\n",
    "    labels = []\n",
    "\n",
    "    for i in range(S):\n",
    "        for j in range(S):\n",
    "            cell_output = encoded_labels[i, j]\n",
    "            bbox = cell_output[:4]\n",
    "            conf = cell_output[4]\n",
    "            class_probs = cell_output[5:]\n",
    "\n",
    "            x_cell, y_cell, w_cell, h_cell = bbox\n",
    "            x = (j + x_cell) / S\n",
    "            y = (i + y_cell) / S\n",
    "            w = w_cell**2\n",
    "            h = h_cell**2\n",
    "            cx, cy = x + w * 0.5, y + h * 0.5\n",
    "\n",
    "            class_idx = torch.argmax(class_probs)\n",
    "            class_prob = class_probs[class_idx] * conf\n",
    "\n",
    "            # print(class_idx, class_prob, conf)\n",
    "            # return\n",
    "\n",
    "            if class_prob > conf_th:\n",
    "                box = torch.tensor(\n",
    "                    [\n",
    "                        class_idx.item(),\n",
    "                        cx,\n",
    "                        cy,\n",
    "                        w,\n",
    "                        h,\n",
    "                        conf,\n",
    "                        class_prob.item(),\n",
    "                    ]\n",
    "                )\n",
    "                labels.append(box.unsqueeze(0))\n",
    "\n",
    "    results = torch.empty(size=(0, 7), dtype=torch.float32)\n",
    "    if labels:\n",
    "        results = torch.cat(labels, dim=0)\n",
    "        if nms:\n",
    "            results = apply_nms(results, iou_th)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "d9f846e9-e419-4678-a057-02d987cee8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_vec(encoded_labels,\n",
    "               S=3, B=2, C=2, prob_th=0.1,\n",
    "               nms=True, iou_th=0.5):\n",
    "    \"\"\"\n",
    "    ip shape: [S, S, B*5 + C]\n",
    "    \"\"\"\n",
    "    if encoded_labels.numel() \n",
    "    # view shape: [S*S, B*5 + C]\n",
    "    \n",
    "    encoded_labels = encoded_labels.view(S*S, -1)\n",
    "    # extracted cell boxes shape: [S*S*B, 5]\n",
    "    boxes = encoded_labels[:, :B*5].reshape(S*S*B, -1)\n",
    "    # decoding OHE class probs\n",
    "    class_probs, class_idx = torch.max(encoded_labels[:, -C:], dim=-1, keepdim=True)\n",
    "    class_probs = class_probs.repeat_interleave(B, dim=0)\n",
    "    class_idx = class_idx.repeat_interleave(B, dim=0)\n",
    "    # shape: [S*S*B, 7]\n",
    "    boxes_and_probs = torch.cat([class_idx, boxes, class_probs], dim=-1)\n",
    "\n",
    "    # decoding boxes to cxcywh format\n",
    "    i = torch.arange(S).repeat_interleave(S*B)\n",
    "    j = torch.arange(S).repeat(S).repeat_interleave(B)\n",
    "    x = ((boxes_and_probs[:, 1] + i) / S) + boxes_and_probs[:, 3]*0.5\n",
    "    \n",
    "    # w and h were square rooted during encoding.\n",
    "    boxes_and_probs[:, 3:5].pow_(2)\n",
    "    boxes_and_probs[:, 1] = ((boxes_and_probs[:, 1] + j) / S) + boxes_and_probs[:, 3]*0.5\n",
    "    boxes_and_probs[:, 2] = ((boxes_and_probs[:, 2] + i) / S) + boxes_and_probs[:, 4]*0.5\n",
    "    # p(class) = p(class | obj) * p(obj)\n",
    "    boxes_and_probs[:, -1] *= boxes_and_probs[:, 5]\n",
    "    prob_mask = boxes_and_probs[:, -1] > prob_th\n",
    "    valid_boxes_and_probs = boxes_and_probs[prob_mask]\n",
    "\n",
    "    print(valid_boxes_and_probs.shape)\n",
    "    return valid_boxes_and_probs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "38dbafb5-33b0-4d35-bcaf-06a4dfe2c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "S, B, C = 3, 1, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "cd7528c8-2a49-45e1-9172-bd7d73dae7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = torch.rand(S, S, B*5 + C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "cc5cf64d-4032-4669-bc90-2451d2cb9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded0 = decode_labelsv0(ip, S, B, C, conf_th=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea555b9a-0e8a-4c88-92ce-58ab0309f12b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664aad15-c30a-4a10-9839-22f06e576592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "19e8f1c7-78b4-47d4-be7a-084283adad75",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "max(): Expected reduction dim 1 to have non-zero size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[281], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m decoded \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprob_th\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[278], line 13\u001b[0m, in \u001b[0;36mdecode_vec\u001b[0;34m(encoded_labels, S, B, C, prob_th, nms, iou_th)\u001b[0m\n\u001b[1;32m     11\u001b[0m boxes \u001b[38;5;241m=\u001b[39m encoded_labels[:, :B\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(S\u001b[38;5;241m*\u001b[39mS\u001b[38;5;241m*\u001b[39mB, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# decoding OHE class probs\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m class_probs, class_idx \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m class_probs \u001b[38;5;241m=\u001b[39m class_probs\u001b[38;5;241m.\u001b[39mrepeat_interleave(B, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     15\u001b[0m class_idx \u001b[38;5;241m=\u001b[39m class_idx\u001b[38;5;241m.\u001b[39mrepeat_interleave(B, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: max(): Expected reduction dim 1 to have non-zero size."
     ]
    }
   ],
   "source": [
    "decoded = decode_vec(torch.tensor([]), S, B, C, prob_th=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "25c69e86-b6d0-4cc9-9a77-e89ce93a66f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0000, 0.6329, 0.2927, 0.0034, 0.3312, 0.2901, 0.2232])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded0[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "31fa2555-d500-475b-85a6-24162882e300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0000, 0.6329, 0.2927, 0.0034, 0.3312, 0.2901, 0.2232])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "dfcc8919-a025-4f30-8617-edef92022226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded == decoded0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "9e45c533-bd05-4afe-9ccc-061a765881a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec02d3f4-38e3-4a99-ad4a-b75c0071785c",
   "metadata": {},
   "source": [
    "## custom loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "95bd1fac-7e39-4a25-9731-56bc57f31263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0706,  0.0000],\n",
       "        [-1.3386,  1.0000],\n",
       "        [ 0.2133,  2.0000],\n",
       "        [-1.3419,  3.0000],\n",
       "        [-0.5589,  4.0000],\n",
       "        [ 0.2992,  5.0000],\n",
       "        [-0.7575,  6.0000],\n",
       "        [ 1.2572,  7.0000],\n",
       "        [-0.3777,  8.0000],\n",
       "        [-0.1400,  9.0000]])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "69de5116-154f-4457-a082-541013a2fffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0706,  0.0000,  1.0706,  0.0000],\n",
       "        [-1.3386,  1.0000, -1.3386,  1.0000],\n",
       "        [ 0.2133,  2.0000,  0.2133,  2.0000],\n",
       "        [-1.3419,  3.0000, -1.3419,  3.0000],\n",
       "        [-0.5589,  4.0000, -0.5589,  4.0000],\n",
       "        [ 0.2992,  5.0000,  0.2992,  5.0000],\n",
       "        [-0.7575,  6.0000, -0.7575,  6.0000],\n",
       "        [ 1.2572,  7.0000,  1.2572,  7.0000],\n",
       "        [-0.3777,  8.0000, -0.3777,  8.0000],\n",
       "        [-0.1400,  9.0000, -0.1400,  9.0000]])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs.repeat(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "86a574ab-f9b9-4523-bded-071f3c492eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, S, B, C = 2, 3, 2, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "15762a96-dee0-42a9-84d7-0f6783d38e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.rand(N, S, S, B*5 + C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "3b14f0e7-0201-499d-851c-86ac255ae6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.rand(N, S, S, B*5 + C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "cdf3f05f-6b7c-4b67-8722-60ee1281036a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3, 14])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "65ee37cc-e69b-4cf9-8bd5-e604cdda4fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_obj_exists = targets[..., 4] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "e2de5d3f-6c1e-40af-8bb0-1dee01bf26b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_obj_exists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "9ab72419-8430-48f4-8d74-16f3da36f7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0706,  0.0000],\n",
       "        [-1.3386,  1.0000],\n",
       "        [ 0.2133,  2.0000],\n",
       "        [-1.3419,  3.0000],\n",
       "        [-0.5589,  4.0000],\n",
       "        [ 0.2992,  5.0000],\n",
       "        [-0.7575,  6.0000],\n",
       "        [ 1.2572,  7.0000],\n",
       "        [-0.3777,  8.0000],\n",
       "        [-0.1400,  9.0000]])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "c77a6e0e-57f4-49d3-9637-72608f7e9954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0706],\n",
       "        [1.0000],\n",
       "        [2.0000],\n",
       "        [3.0000],\n",
       "        [4.0000],\n",
       "        [5.0000],\n",
       "        [6.0000],\n",
       "        [7.0000],\n",
       "        [8.0000],\n",
       "        [9.0000]])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs.max(dim=1, keepdim=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "4ba9a2e0-0a51-484a-8e06-46c35c34d931",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(N, S*S, B, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "320bec83-c68e-4534-a76a-6824bb652c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9, 2, 7])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "0024531a-9f6d-4ec2-8a54-b406a6702b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = x[..., 5] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "3b2c182a-d4ef-4225-91d5-e8b59f5a1c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9, 2])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "200d2148-defd-45c0-afe8-d3fda342c9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask2 = torch.ones(2, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "e7c56f0a-5d27-4371-9cc6-6e2887dc1e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "92477267-8852-451f-b5cf-e90b287d1f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9, 2, 9, 2, 7])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[mask.int()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "13ab579b-1f86-4ab6-a31c-2788065c5d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9, 2, 7])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "022c29d3-41a0-4643-ab77-9edbe29cbcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_iou(pred_boxes, target_boxes):\n",
    "    pred_x1 = pred_boxes[..., 0] - pred_boxes[..., 2] / 2\n",
    "    pred_y1 = pred_boxes[..., 1] - pred_boxes[..., 3] / 2\n",
    "    pred_x2 = pred_boxes[..., 0] + pred_boxes[..., 2] / 2\n",
    "    pred_y2 = pred_boxes[..., 1] + pred_boxes[..., 3] / 2\n",
    "\n",
    "    target_x1 = target_boxes[..., 0] - target_boxes[..., 2] / 2\n",
    "    target_y1 = target_boxes[..., 1] - target_boxes[..., 3] / 2\n",
    "    target_x2 = target_boxes[..., 0] + target_boxes[..., 2] / 2\n",
    "    target_y2 = target_boxes[..., 1] + target_boxes[..., 3] / 2\n",
    "\n",
    "    inter_x1 = torch.max(pred_x1, target_x1)\n",
    "    inter_y1 = torch.max(pred_y1, target_y1)\n",
    "    inter_x2 = torch.min(pred_x2, target_x2)\n",
    "    inter_y2 = torch.min(pred_y2, target_y2)\n",
    "\n",
    "    inter_area = torch.clamp(inter_x2 - inter_x1, min=0) * torch.clamp(inter_y2 - inter_y1, min=0)\n",
    "\n",
    "    pred_area = (pred_x2 - pred_x1) * (pred_y2 - pred_y1)\n",
    "    target_area = (target_x2 - target_x1) * (target_y2 - target_y1)\n",
    "\n",
    "    union_area = pred_area + target_area - inter_area\n",
    "\n",
    "    iou = inter_area / union_area\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "e29c3c37-68f9-4ebb-931f-453fd9fffd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(preds, targets, S, B, C):\n",
    "    \"\"\"\n",
    "    preds, targets: [N, S, S, B*5 + C]\n",
    "    \"\"\"\n",
    "    mse = torch.nn.MSELoss(reduction=\"sum\")\n",
    "    # shape: [N, S*S*B, 7] in (class_idx, cx, cy, w, h, conf, cond_cls_prob)\n",
    "    N = len(targets)\n",
    "    decoded_preds = torch.stack([\n",
    "        decode_labels(x, S, B, C, prob_th=-1, nms=False)\n",
    "        for x in preds])\n",
    "    decoded_targets = torch.stack([\n",
    "        decode_labels(x, S, B, C, prob_th=-1, nms=False)\n",
    "        for x in targets])\n",
    "    last_dim_sz = decoded_targets.shape[-1]\n",
    "    \n",
    "    # obj mask shape: [N, S*S*B, 7]\n",
    "    mask_obj_exists = decoded_targets[..., 5] > 0\n",
    "    mask_obj_exists = mask_obj_exists.unsqueeze(-1).expand_as(decoded_targets)\n",
    "    # print(mask_obj_exists)\n",
    "\n",
    "    # shape: [N, K, 4] K is a multiple of B since we had 3 times\n",
    "    preds_cls_filtered = preds.view(N, S*S, -1)[..., -C]\n",
    "    # preds_cls_filtered[\n",
    "    \n",
    "    preds_filtered = decoded_preds[mask_obj_exists].view(N, -1, last_dim_sz)\n",
    "    targets_filtered = decoded_targets[mask_obj_exists].view(N, -1, last_dim_sz)\n",
    "    preds_unfiltered = decoded_preds[~mask_obj_exists].view(N, -1, last_dim_sz)\n",
    "    targets_unfiltered = decoded_targets[~mask_obj_exists].view(N, -1, last_dim_sz)\n",
    "\n",
    "    # shape: [N*K]\n",
    "    ious = calc_iou(preds_filtered[..., 1:5].reshape(-1, 4), \n",
    "                    targets_filtered[..., 1:5].reshape(-1, 4))\n",
    "    \n",
    "    # shape: [N, K/B, B]\n",
    "    ious = ious.reshape(N, -1, B)\n",
    "\n",
    "    # shape: [N, K, 4]\n",
    "    _, best_iou_idx = torch.max(ious, dim=-1, keepdim=False)\n",
    "    best_iou_mask = torch.zeros_like(ious)\n",
    "    best_iou_mask = best_iou_mask.scatter(-1, \n",
    "                                          best_iou_idx.unsqueeze(-1), \n",
    "                                          1,\n",
    "                                         ).reshape(N, -1)\n",
    "    best_iou_mask = best_iou_mask.unsqueeze(-1).bool()\n",
    "\n",
    "    # coord loss\n",
    "    pred_boxes = preds_filtered[..., 1:5]\n",
    "    target_boxes = targets_filtered[..., 1:5]\n",
    "    resp_pred_boxes = pred_boxes[best_iou_mask.expand_as(pred_boxes)].view(-1, 4)\n",
    "    resp_target_boxes = target_boxes[best_iou_mask.expand_as(target_boxes)].view(-1, 4)\n",
    "    \n",
    "    coord_loss = mse(resp_pred_boxes, resp_target_boxes)\n",
    "\n",
    "    # obj loss\n",
    "    pred_confs = preds_filtered[..., 5:6]\n",
    "    target_confs = targets_filtered[..., 5:6]\n",
    "    resp_pred_confs = pred_confs[best_iou_mask.expand_as(pred_confs)].view(-1, 1)\n",
    "    resp_target_confs = target_confs[best_iou_mask.expand_as(target_confs)].view(-1, 1)\n",
    "\n",
    "    obj_loss = mse(resp_pred_confs, resp_target_confs)\n",
    "\n",
    "    # noobj loss\n",
    "    noobj_pred_confs = preds_unfiltered[..., 5:6]\n",
    "    noobj_target_confs = targets_unfiltered[..., 5:6]\n",
    "    nonresp_pred_confs = pred_confs[~best_iou_mask.expand_as(pred_confs)].view(N, -1, 1)\n",
    "    nonresp_target_confs = torch.zeros_like(nonresp_pred_confs)\n",
    "    noobj_pred_confs = torch.cat([noobj_pred_confs, nonresp_pred_confs], dim=1)\n",
    "    noobj_target_confs = torch.cat([noobj_target_confs, nonresp_target_confs], dim=1)\n",
    "\n",
    "    noobj_loss = mse(noobj_pred_confs, noobj_target_confs)\n",
    "\n",
    "    # class loss\n",
    "    mask_cls = mask_obj_exists.reshape(N, S, S, -1)[..., 0:1].expand_as(preds)\n",
    "    pred_cls_probs = preds[mask_cls][..., -C:]\n",
    "    target_cls_probs = targets[mask_cls][..., -C:]\n",
    "    \n",
    "    cls_loss = mse(pred_cls_probs, target_cls_probs)\n",
    "    \n",
    "    print(obj_loss, coord_loss, noobj_loss, cls_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "444ca2c0-15f6-476b-bc6b-ae8edd483b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yolov1\n",
    "import pprint\n",
    "from yolov1.config import parse_config\n",
    "from yolov1.data.dataset import YOLODataset\n",
    "from yolov1.utils.general import decode_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "dc271df9-f5ec-4ea0-82a2-4dabd7f8ffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(show=False):\n",
    "    config_path = \"../../yolov1/src/yolov1/configs/default.yaml\"\n",
    "    config = parse_config(config_file=config_path)\n",
    "    if show:\n",
    "        pprint.pp(config.dict())\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "1e569286-2dfd-43e7-9eec-106b6bd74750",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "f5ce79f6-b13c-48d9-a688-601fc89a0229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 5)"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S, B, C = config.model.S, config.model.B, config.model.nc\n",
    "S, B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "fe8bed97-689c-4439-a49a-c4701cdc267b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-05-16T18:40:42.708574Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mLoaded 250 samples            \u001b[0m \u001b[36mfunc_name\u001b[0m=\u001b[35mget_data\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m88\u001b[0m\n",
      "\u001b[2m2024-05-16T18:40:42.709084Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mClass weights: [0.4, 0.24, 0.12, 0.36, 0.32]\u001b[0m \u001b[36mfunc_name\u001b[0m=\u001b[35m_set_class_weights\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m56\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "val_ds = YOLODataset(config, mode=\"valid\", encode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "a3962a55-6e4e-47fe-aefc-38a6602c5a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "first = val_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "c54db002-606b-4ea6-a205-8d9d18c350b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_targets = first[1].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "4e1ec559-e925-4ff2-b2cc-b934b681d296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3, 15])"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "5bc79dfd-efc7-48bb-84a5-b4bde7c961d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.6677, 0.9285, 0.3968, 0.4891, 1.0000, 0.6677, 0.9285, 0.3968,\n",
       "           0.4891, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n",
       "          [0.7224, 0.8041, 0.1297, 0.1387, 1.0000, 0.7224, 0.8041, 0.1297,\n",
       "           0.1387, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0018, 0.0349, 0.5894, 0.5119, 1.0000, 0.0018, 0.0349, 0.5894,\n",
       "           0.5119, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n",
       "          [0.8624, 0.4008, 0.6140, 0.7286, 1.0000, 0.8624, 0.4008, 0.6140,\n",
       "           0.7286, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]])"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "31e61f04-7316-4e98-bbda-cd5e9105952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.rand(2, S, S, B*5 + C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "40a1e331-df57-4e07-8029-90546f914152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3, 15])"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "b6a53603-139f-48cd-906b-7b3f13938713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9260, 0.1062, 0.4728, 0.4427, 0.4072, 0.0135, 0.3873, 0.8887,\n",
       "           0.6450, 0.9028, 0.5523, 0.4007, 0.1212, 0.6134, 0.9612],\n",
       "          [0.2879, 0.8812, 0.0099, 0.2160, 0.5365, 0.8191, 0.0318, 0.6130,\n",
       "           0.0723, 0.3746, 0.3100, 0.1695, 0.0492, 0.3387, 0.6989],\n",
       "          [0.8175, 0.5271, 0.2679, 0.8604, 0.5091, 0.6466, 0.9669, 0.0662,\n",
       "           0.7394, 0.3783, 0.2177, 0.0232, 0.4700, 0.0303, 0.3568]],\n",
       "\n",
       "         [[0.3673, 0.8453, 0.3735, 0.0249, 0.1917, 0.8579, 0.3690, 0.4156,\n",
       "           0.2589, 0.9686, 0.5306, 0.5124, 0.4264, 0.1917, 0.4729],\n",
       "          [0.5257, 0.1256, 0.0782, 0.9726, 0.4917, 0.3759, 0.5928, 0.9342,\n",
       "           0.4513, 0.9643, 0.3129, 0.0758, 0.7433, 0.5578, 0.5049],\n",
       "          [0.0554, 0.2177, 0.1641, 0.6000, 0.8540, 0.7621, 0.3091, 0.2649,\n",
       "           0.0534, 0.6133, 0.3350, 0.3696, 0.8832, 0.7284, 0.3935]],\n",
       "\n",
       "         [[0.6074, 0.8624, 0.6181, 0.0153, 0.0486, 0.8517, 0.1839, 0.4805,\n",
       "           0.3152, 0.7925, 0.1649, 0.9371, 0.7676, 0.7113, 0.0796],\n",
       "          [0.0619, 0.1636, 0.8958, 0.9092, 0.6068, 0.0270, 0.9229, 0.0461,\n",
       "           0.5821, 0.3229, 0.0783, 0.6652, 0.3597, 0.3227, 0.4885],\n",
       "          [0.5780, 0.3538, 0.9583, 0.3262, 0.5368, 0.9921, 0.1028, 0.6919,\n",
       "           0.2518, 0.8683, 0.8705, 0.5849, 0.6782, 0.5475, 0.5853]]],\n",
       "\n",
       "\n",
       "        [[[0.1492, 0.9500, 0.0425, 0.7628, 0.4011, 0.8970, 0.7983, 0.3379,\n",
       "           0.8910, 0.8048, 0.0863, 0.4443, 0.4169, 0.1245, 0.7282],\n",
       "          [0.3121, 0.2512, 0.7370, 0.1825, 0.8226, 0.4038, 0.8245, 0.1920,\n",
       "           0.2310, 0.4509, 0.5473, 0.3233, 0.0996, 0.9930, 0.6347],\n",
       "          [0.5636, 0.2174, 0.3151, 0.4550, 0.6145, 0.9756, 0.7969, 0.0059,\n",
       "           0.8568, 0.2218, 0.3930, 0.4861, 0.3916, 0.4867, 0.8909]],\n",
       "\n",
       "         [[0.2382, 0.3884, 0.3928, 0.6349, 0.7905, 0.2155, 0.6170, 0.3213,\n",
       "           0.4959, 0.8807, 0.3102, 0.7700, 0.5766, 0.5595, 0.1659],\n",
       "          [0.0993, 0.0146, 0.5050, 0.2975, 0.8186, 0.0278, 0.8894, 0.5804,\n",
       "           0.1661, 0.6742, 0.6479, 0.4223, 0.4691, 0.3276, 0.6274],\n",
       "          [0.7011, 0.7872, 0.0205, 0.3238, 0.0267, 0.5452, 0.1689, 0.1208,\n",
       "           0.5368, 0.8952, 0.0547, 0.0658, 0.9492, 0.6071, 0.0629]],\n",
       "\n",
       "         [[0.1820, 0.2101, 0.7305, 0.8763, 0.2247, 0.6508, 0.0202, 0.7132,\n",
       "           0.2775, 0.1743, 0.1048, 0.5978, 0.6625, 0.6961, 0.8282],\n",
       "          [0.0310, 0.3899, 0.0192, 0.3989, 0.6600, 0.4688, 0.8342, 0.6597,\n",
       "           0.9372, 0.5811, 0.8439, 0.6524, 0.5765, 0.5224, 0.0505],\n",
       "          [0.3763, 0.7760, 0.4528, 0.8987, 0.7038, 0.9007, 0.3731, 0.8743,\n",
       "           0.0437, 0.9108, 0.9732, 0.8902, 0.4940, 0.4970, 0.6637]]]])"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "6d0e199b-f238-4741-a1e4-78897b6a8c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3, 15]) torch.Size([2, 3, 3, 15])\n",
      "tensor(0.7881) tensor(1.9949) tensor(10.2811) tensor(1.3809)\n"
     ]
    }
   ],
   "source": [
    "loss(preds, torch.cat([encoded_targets,\n",
    "                        encoded_targets]), S, B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "3dda4eaf-68b8-4009-a11e-131f3ed024ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3, 15]) torch.Size([1, 3, 3, 15])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [1, 18, 7] at index 0 does not match the shape of the indexed tensor [2, 18, 7] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[609], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[608], line 26\u001b[0m, in \u001b[0;36mloss\u001b[0;34m(preds, targets, S, B, C)\u001b[0m\n\u001b[1;32m     23\u001b[0m preds_cls_filtered \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mview(N, S\u001b[38;5;241m*\u001b[39mS, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m-\u001b[39mC]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# preds_cls_filtered[\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m preds_filtered \u001b[38;5;241m=\u001b[39m \u001b[43mdecoded_preds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask_obj_exists\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mview(N, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, last_dim_sz)\n\u001b[1;32m     27\u001b[0m targets_filtered \u001b[38;5;241m=\u001b[39m decoded_targets[mask_obj_exists]\u001b[38;5;241m.\u001b[39mview(N, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, last_dim_sz)\n\u001b[1;32m     28\u001b[0m preds_unfiltered \u001b[38;5;241m=\u001b[39m decoded_preds[\u001b[38;5;241m~\u001b[39mmask_obj_exists]\u001b[38;5;241m.\u001b[39mview(N, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, last_dim_sz)\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [1, 18, 7] at index 0 does not match the shape of the indexed tensor [2, 18, 7] at index 0"
     ]
    }
   ],
   "source": [
    "loss(preds, encoded_targets, S, B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "f5843947-cb09-4c49-9e14-ac788f2198eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = torch.tensor([0.0009, 0.0696, 0.0000, 0.0000, 0.0540, 0.0791, 0.0000, 0.1470])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "dd459a1a-892b-4238-8c13-5bebd6335593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "d6aa2c9e-98ce-40f8-99d8-8bfb928cda8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0009, 0.0696, 0.0000, 0.0000, 0.0540, 0.0791, 0.0000, 0.1470])"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "d5b8214c-9b26-4210-8bd4-738f726c2cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = torch.tensor([[1, 0, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "3eacdc49-9343-4ec9-a3e4-9c548ac403ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_mask = torch.zeros_like(xx).reshape(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "11c92639-8a2f-49ae-8508-6f1fcfb2ef5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "e23aee90-5b9f-4e6b-aeb2-1072ebfc120d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 1., 0., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_mask.scatter(1, yy.reshape(4, 1), 1).reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "51dabd0f-3053-4ee0-ac0f-a0e1f83ecca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1014, 0.3509, 0.7096, 0.3590, 0.5059, 0.8760, 0.4589, 0.4028,\n",
       "           0.1521, 0.9241, 0.5535, 0.6976, 0.5283, 0.1457, 0.7197],\n",
       "          [0.4522, 0.4449, 0.2687, 0.8649, 0.4985, 0.6969, 0.3481, 0.8812,\n",
       "           0.8068, 0.5763, 0.6155, 0.0775, 0.8457, 0.9575, 0.4400],\n",
       "          [0.0173, 0.3034, 0.9779, 0.3435, 0.9939, 0.2570, 0.2705, 0.9680,\n",
       "           0.1560, 0.5211, 0.2091, 0.1780, 0.6047, 0.8249, 0.7159]],\n",
       "\n",
       "         [[0.6490, 0.6258, 0.4817, 0.5723, 0.9932, 0.7217, 0.4252, 0.3292,\n",
       "           0.9708, 0.4000, 0.2672, 0.8188, 0.9201, 0.4729, 0.3722],\n",
       "          [0.5451, 0.7504, 0.2668, 0.9280, 0.9178, 0.2815, 0.9798, 0.9263,\n",
       "           0.9619, 0.4463, 0.4913, 0.0248, 0.2675, 0.8094, 0.1555],\n",
       "          [0.8827, 0.4363, 0.6274, 0.2234, 0.4448, 0.0914, 0.3879, 0.4188,\n",
       "           0.7209, 0.3812, 0.4332, 0.3124, 0.2081, 0.4082, 0.1410]],\n",
       "\n",
       "         [[0.0971, 0.9668, 0.5396, 0.1257, 0.2578, 0.9445, 0.7895, 0.7754,\n",
       "           0.4941, 0.9910, 0.1739, 0.5148, 0.6078, 0.1965, 0.1323],\n",
       "          [0.0042, 0.4674, 0.3461, 0.8338, 0.6893, 0.2801, 0.0066, 0.5797,\n",
       "           0.1153, 0.7056, 0.8637, 0.5726, 0.1934, 0.0818, 0.9683],\n",
       "          [0.1923, 0.3031, 0.8781, 0.6230, 0.9232, 0.0991, 0.5747, 0.6542,\n",
       "           0.1665, 0.9244, 0.5215, 0.1906, 0.5159, 0.3868, 0.0612]]]])"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "026ff888-ee3c-4fd6-9547-ff98fff4dc9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 18, -1]' is invalid for input of size 135",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[567], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpreds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mS\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 18, -1]' is invalid for input of size 135"
     ]
    }
   ],
   "source": [
    "preds.view(1, S*S*B, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "8ec9bd09-4b82-4584-a905-a2da3f5a2b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3, 15])"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "46ff3d21-0ed4-4d08-a726-2dbe4fcb772b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "96/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc6c91c-f795-4da5-a1f9-6519f7e5a908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
